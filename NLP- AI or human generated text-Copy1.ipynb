{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0282186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37efda27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...          0\n",
       "1  Transportation is a large necessity in most co...          0\n",
       "2  \"America's love affair with it's vehicles seem...          0\n",
       "3  How often do you ride in a car? Do you drive a...          0\n",
       "4  Cars are a wonderful thing. They are perhaps o...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\dkdes\\OneDrive\\Desktop\\kaggle_datasets\\large AI_Human Text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2126e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.sample(1000,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1143529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 11006 to 314444\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       1000 non-null   object\n",
      " 1   generated  1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f745c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    633\n",
       "1    367\n",
       "Name: generated, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"generated\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d15359e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.633"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"generated\"].value_counts()[0]/df1[\"generated\"].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f07fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.367"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"generated\"].value_counts()[1]/df1[\"generated\"].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1bab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    305797\n",
       "1    181438\n",
       "Name: generated, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"generated\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ea6e0",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c81dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11006     nasa noticed something unfimiliar on the red p...\n",
       "486485    to many people it was confusing, but to me, it...\n",
       "470298    advantages of limiting car usage\\n\\nlimiting c...\n",
       "19968     \\n\\nworking with a group can be menacing and r...\n",
       "10207     recently we have discovered a new landform on ...\n",
       "                                ...                        \n",
       "91063     dear state senator,\\n\\ni think that changing t...\n",
       "278866    dear, teacher_name\\n\\ni am aware of the your d...\n",
       "435779    there is a debate whether electoral cortege sh...\n",
       "265478    the open seas await\\n\\nwhen i first joined the...\n",
       "314444    have you even looked at someone and thought, i...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c7dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"text\"]=df1[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb49da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>nasa noticed something unfimiliar on the red p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486485</th>\n",
       "      <td>to many people it was confusing, but to me, it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470298</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>\\n\\nworking with a group can be menacing and r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>recently we have discovered a new landform on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367556</th>\n",
       "      <td>title:\"become a seagoing cowboy of a lifetime\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478101</th>\n",
       "      <td>dear [state senator],\\n\\ni am writing to expr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484783</th>\n",
       "      <td>x am luke merger and x have been to unique pla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454480</th>\n",
       "      <td>students learn better if they are interested i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463534</th>\n",
       "      <td>there are a few reason why younger people migh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated\n",
       "11006   nasa noticed something unfimiliar on the red p...          0\n",
       "486485  to many people it was confusing, but to me, it...          0\n",
       "470298  advantages of limiting car usage\\n\\nlimiting c...          1\n",
       "19968   \\n\\nworking with a group can be menacing and r...          1\n",
       "10207   recently we have discovered a new landform on ...          0\n",
       "367556  title:\"become a seagoing cowboy of a lifetime\"...          0\n",
       "478101   dear [state senator],\\n\\ni am writing to expr...          1\n",
       "484783  x am luke merger and x have been to unique pla...          0\n",
       "454480  students learn better if they are interested i...          0\n",
       "463534  there are a few reason why younger people migh...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a87f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing html tags if any \n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e155cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b4aa0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>nasa noticed something unfimiliar on the red p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486485</th>\n",
       "      <td>to many people it was confusing, but to me, it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470298</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>\\n\\nworking with a group can be menacing and r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>recently we have discovered a new landform on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated\n",
       "11006   nasa noticed something unfimiliar on the red p...          0\n",
       "486485  to many people it was confusing, but to me, it...          0\n",
       "470298  advantages of limiting car usage\\n\\nlimiting c...          1\n",
       "19968   \\n\\nworking with a group can be menacing and r...          1\n",
       "10207   recently we have discovered a new landform on ...          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395bd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d380447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104cd1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>nasa noticed something unfimiliar on the red p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486485</th>\n",
       "      <td>to many people it was confusing, but to me, it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470298</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>\\n\\nworking with a group can be menacing and r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>recently we have discovered a new landform on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated\n",
       "11006   nasa noticed something unfimiliar on the red p...          0\n",
       "486485  to many people it was confusing, but to me, it...          0\n",
       "470298  advantages of limiting car usage\\n\\nlimiting c...          1\n",
       "19968   \\n\\nworking with a group can be menacing and r...          1\n",
       "10207   recently we have discovered a new landform on ...          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53d81ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation\n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb04da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d722e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eede3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>nasa noticed something unfimiliar on the red p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486485</th>\n",
       "      <td>to many people it was confusing but to me it w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470298</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>\\n\\nworking with a group can be menacing and r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>recently we have discovered a new landform on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91063</th>\n",
       "      <td>dear state senator\\n\\ni think that changing to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278866</th>\n",
       "      <td>dear teachername\\n\\ni am aware of the your dil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435779</th>\n",
       "      <td>there is a debate whether electoral cortege sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265478</th>\n",
       "      <td>the open seas await\\n\\nwhen i first joined the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314444</th>\n",
       "      <td>have you even looked at someone and thought i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated\n",
       "11006   nasa noticed something unfimiliar on the red p...          0\n",
       "486485  to many people it was confusing but to me it w...          0\n",
       "470298  advantages of limiting car usage\\n\\nlimiting c...          1\n",
       "19968   \\n\\nworking with a group can be menacing and r...          1\n",
       "10207   recently we have discovered a new landform on ...          0\n",
       "...                                                   ...        ...\n",
       "91063   dear state senator\\n\\ni think that changing to...          0\n",
       "278866  dear teachername\\n\\ni am aware of the your dil...          0\n",
       "435779  there is a debate whether electoral cortege sh...          0\n",
       "265478  the open seas await\\n\\nwhen i first joined the...          1\n",
       "314444  have you even looked at someone and thought i ...          0\n",
       "\n",
       "[951 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1[\"text\"].str.contains(\"\\n\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949952ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text']=df1[\"text\"].str.replace(\"\\n\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6bcf086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, generated]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1[\"text\"].str.contains(\"\\n\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a16705",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek You (also a chat program)\",\n",
    "    \"ILU\": \"I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laugh My A.. Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A..\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA?\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your sex and age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That feeling when\",\n",
    "    \"MFW\": \"My face when\",\n",
    "    \"MRW\": \"My reaction when\",\n",
    "    \"IFYP\": \"I feel your pain\",\n",
    "    \"LOL\": \"Laughing out loud\",\n",
    "    \"TNTL\": \"Trying not to laugh\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"IDC\": \"I don’t care\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"IMU\": \"I miss you\",\n",
    "    \"ADIH\": \"Another day in hell\",\n",
    "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "    \"WYWH\": \"Wish you were here\",\n",
    "    \"TIME\": \"Tears in my eyes\",\n",
    "    \"BAE\": \"Before anyone else\",\n",
    "    \"FIMH\": \"Forever in my heart\",\n",
    "    \"BSAAW\": \"Big smile and a wink\",\n",
    "    \"BWL\": \"Bursting with laughter\",\n",
    "    \"LMAO\": \"Laughing my a** off\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"CSL\": \"Can’t stop laughing\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d8a0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    \n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59aa626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Honest/Humble Opinion he is the best'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('IMHO he is the best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f03ce7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726d493b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>nasa noticed something unfimiliar on the red p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486485</th>\n",
       "      <td>to many people it was confusing but to me it w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470298</th>\n",
       "      <td>advantages of limiting car usagelimiting car u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>working with a group can be menacing and rewar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>recently we have discovered a new landform on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated\n",
       "11006   nasa noticed something unfimiliar on the red p...          0\n",
       "486485  to many people it was confusing but to me it w...          0\n",
       "470298  advantages of limiting car usagelimiting car u...          1\n",
       "19968   working with a group can be menacing and rewar...          1\n",
       "10207   recently we have discovered a new landform on ...          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc02d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0df3e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0376efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7dfa3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e310162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1333701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  generated\n",
      "11006   nasa notice something unfimiliar red planet ca...          0\n",
      "486485  many people confuse life every night would com...          0\n",
      "470298  advantage limit car usagelimite car usage brin...          1\n",
      "19968   work group menacing rewarding equal measure on...          1\n",
      "10207   recently discover new landform mar vike 1 catc...          0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        doc = nlp(text)\n",
    "        return \" \".join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])\n",
    "    else:\n",
    "        return text  # Return the text as-is if it's not a string\n",
    "\n",
    "# Create a sample pandas DataFrame\n",
    "data = {'text_column': [\"This is a sample text.\", \"Here is another sentence.\", 12345, None]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert all values in the DataFrame column to strings\n",
    "df1['text'] = df1['text'].astype(str)\n",
    "\n",
    "# Apply the lemmatization function to the DataFrame column\n",
    "df1['text'] = df1['text'].apply(lemmatize_text)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df1.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b62a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1[\"text\"]\n",
    "y=df1[\"generated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fc88d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b4f8fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 11771)\n",
      "(200, 11771)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfv = TfidfVectorizer()\n",
    "\n",
    "# Fit the TfidfVectorizer only on the training data\n",
    "tfv.fit(X_train)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_tfv = tfv.transform(X_train)\n",
    "X_test_tfv = tfv.transform(X_test)\n",
    "\n",
    "# Print the shape of the transformed data\n",
    "print(X_train_tfv.shape)\n",
    "print(X_test_tfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "855667d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name(a):\n",
    "    model=a\n",
    "    model.fit(X_train_tfv, y_train)\n",
    "    y_pred=model.predict(X_test_tfv)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    f1=f1_score(y_test,y_pred)\n",
    "    print(\"accuracy:\",accuracy)\n",
    "    print(\"f1_score:\",f1)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"model on training data\",np.mean(cross_val_score(model,X_train_tfv,y_train,cv=5,scoring=\"accuracy\")))\n",
    "    print(\"model on testing data\",np.mean(cross_val_score(model,X_test_tfv,y_test,cv=5,scoring=\"accuracy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "975c70a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.935\n",
      "f1_score: 0.8849557522123894\n",
      "[[137   1]\n",
      " [ 12  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       138\n",
      "           1       0.98      0.81      0.88        62\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.95      0.90      0.92       200\n",
      "weighted avg       0.94      0.94      0.93       200\n",
      "\n",
      "model on training data 0.9125\n",
      "model on testing data 0.8400000000000001\n"
     ]
    }
   ],
   "source": [
    "model_name(RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f8b137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.93\n",
      "f1_score: 0.8727272727272727\n",
      "[[138   0]\n",
      " [ 14  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       138\n",
      "           1       1.00      0.77      0.87        62\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.95      0.89      0.91       200\n",
      "weighted avg       0.94      0.93      0.93       200\n",
      "\n",
      "model on training data 0.89375\n",
      "model on testing data 0.7249999999999999\n"
     ]
    }
   ],
   "source": [
    "model_name(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1614b046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.955\n",
      "f1_score: 0.9217391304347826\n",
      "[[138   0]\n",
      " [  9  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       138\n",
      "           1       1.00      0.85      0.92        62\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.97      0.93      0.95       200\n",
      "weighted avg       0.96      0.95      0.95       200\n",
      "\n",
      "model on training data 0.9112500000000001\n",
      "model on testing data 0.76\n"
     ]
    }
   ],
   "source": [
    "model_name(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ad2d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n",
      "f1_score: 0.7966101694915254\n",
      "[[129   9]\n",
      " [ 15  47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       138\n",
      "           1       0.84      0.76      0.80        62\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.87      0.85      0.86       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "model on training data 0.85\n",
      "model on testing data 0.8399999999999999\n"
     ]
    }
   ],
   "source": [
    "model_name(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ce6c0",
   "metadata": {},
   "source": [
    "## Training the model with help of Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c0d9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,activation='relu',input_dim=11771))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c31f1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                376704    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32)                128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379233 (1.45 MB)\n",
      "Trainable params: 379041 (1.45 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9301ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",metrics=[\"accuracy\"],loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "739b27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=EarlyStopping(monitor=\"val_loss\",patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f62783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 32ms/step - loss: 0.9654 - accuracy: 0.5578 - val_loss: 0.6846 - val_accuracy: 0.6062\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.8264 - accuracy: 0.5797 - val_loss: 0.6786 - val_accuracy: 0.6062\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.7264 - accuracy: 0.6391 - val_loss: 0.6735 - val_accuracy: 0.6062\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.7059 - accuracy: 0.6531 - val_loss: 0.6678 - val_accuracy: 0.6062\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5834 - accuracy: 0.7141 - val_loss: 0.6613 - val_accuracy: 0.6062\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5587 - accuracy: 0.7312 - val_loss: 0.6540 - val_accuracy: 0.6062\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.5039 - accuracy: 0.7656 - val_loss: 0.6438 - val_accuracy: 0.6062\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4459 - accuracy: 0.8016 - val_loss: 0.6316 - val_accuracy: 0.6062\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.4230 - accuracy: 0.8125 - val_loss: 0.6199 - val_accuracy: 0.6062\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.3591 - accuracy: 0.8422 - val_loss: 0.6063 - val_accuracy: 0.6062\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.3092 - accuracy: 0.8750 - val_loss: 0.5910 - val_accuracy: 0.6062\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2871 - accuracy: 0.8734 - val_loss: 0.5746 - val_accuracy: 0.6062\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2639 - accuracy: 0.8922 - val_loss: 0.5560 - val_accuracy: 0.6062\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2605 - accuracy: 0.9094 - val_loss: 0.5374 - val_accuracy: 0.6313\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2093 - accuracy: 0.9172 - val_loss: 0.5154 - val_accuracy: 0.6562\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2054 - accuracy: 0.9203 - val_loss: 0.4943 - val_accuracy: 0.7188\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1864 - accuracy: 0.9328 - val_loss: 0.4777 - val_accuracy: 0.7375\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1465 - accuracy: 0.9578 - val_loss: 0.4538 - val_accuracy: 0.7563\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 0.9672 - val_loss: 0.4308 - val_accuracy: 0.7875\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1222 - accuracy: 0.9672 - val_loss: 0.4072 - val_accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1201 - accuracy: 0.9609 - val_loss: 0.3934 - val_accuracy: 0.8250\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1221 - accuracy: 0.9672 - val_loss: 0.3730 - val_accuracy: 0.8375\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1283 - accuracy: 0.9609 - val_loss: 0.3545 - val_accuracy: 0.8500\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1089 - accuracy: 0.9688 - val_loss: 0.3242 - val_accuracy: 0.8687\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.3057 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0886 - accuracy: 0.9812 - val_loss: 0.2882 - val_accuracy: 0.9062\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0971 - accuracy: 0.9688 - val_loss: 0.2775 - val_accuracy: 0.9062\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 0.9719 - val_loss: 0.2683 - val_accuracy: 0.9062\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0972 - accuracy: 0.9688 - val_loss: 0.2556 - val_accuracy: 0.9250\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0713 - accuracy: 0.9812 - val_loss: 0.2440 - val_accuracy: 0.9312\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0842 - accuracy: 0.9734 - val_loss: 0.2400 - val_accuracy: 0.9312\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0864 - accuracy: 0.9734 - val_loss: 0.2313 - val_accuracy: 0.9187\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 0.9891 - val_loss: 0.2294 - val_accuracy: 0.9187\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9828 - val_loss: 0.2190 - val_accuracy: 0.9250\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0559 - accuracy: 0.9875 - val_loss: 0.2065 - val_accuracy: 0.9250\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9906 - val_loss: 0.2003 - val_accuracy: 0.9250\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0502 - accuracy: 0.9859 - val_loss: 0.1883 - val_accuracy: 0.9312\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0496 - accuracy: 0.9859 - val_loss: 0.1913 - val_accuracy: 0.9312\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0502 - accuracy: 0.9906 - val_loss: 0.1841 - val_accuracy: 0.9312\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0327 - accuracy: 0.9953 - val_loss: 0.1779 - val_accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0613 - accuracy: 0.9812 - val_loss: 0.1775 - val_accuracy: 0.9312\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0471 - accuracy: 0.9906 - val_loss: 0.1764 - val_accuracy: 0.9312\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.1726 - val_accuracy: 0.9438\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0583 - accuracy: 0.9781 - val_loss: 0.1689 - val_accuracy: 0.9438\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9953 - val_loss: 0.1662 - val_accuracy: 0.9438\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.1619 - val_accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0407 - accuracy: 0.9891 - val_loss: 0.1588 - val_accuracy: 0.9500\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0384 - accuracy: 0.9922 - val_loss: 0.1544 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 0.1590 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0424 - accuracy: 0.9828 - val_loss: 0.1636 - val_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0334 - accuracy: 0.9922 - val_loss: 0.1862 - val_accuracy: 0.9312\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 0.1944 - val_accuracy: 0.9312\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0305 - accuracy: 0.9937 - val_loss: 0.1986 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the sparse matrices to dense arrays\n",
    "X_train_tfv_dense = X_train_tfv.toarray()\n",
    "X_test_tfv_dense = X_test_tfv.toarray()\n",
    "\n",
    "# Fit the model with validation_split\n",
    "history = model.fit(X_train_tfv_dense, y_train, validation_split=0.2, epochs=100, batch_size=52,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1b650c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_dir = 'my_dir'\n",
    "if os.path.exists(tuner_dir):\n",
    "    shutil.rmtree(tuner_dir)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    num_layers = hp.Int(\"num_layers\", min_value=1, max_value=10)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=128, step=8),\n",
    "                activation=hp.Choice(f\"activation_{i}\", values=[\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "                input_dim=11771\n",
    "            ))\n",
    "        else:\n",
    "            model.add(Dense(\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=128, step=8),\n",
    "                activation=hp.Choice(f\"activation_{i}\", values=[\"relu\", \"tanh\", \"sigmoid\"])\n",
    "            ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(rate=hp.Float(f\"dropout_{i}\", min_value=0.0, max_value=0.9, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))  \n",
    "    model.compile(\n",
    "        optimizer=hp.Choice(\"optimizer\", values=[\"adam\", \"rmsprop\", \"sgd\", \"nadam\", \"adadelta\"]),\n",
    "        loss=\"binary_crossentropy\",  \n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "440d56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    directory=tuner_dir,\n",
    "    project_name='my_project'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a144a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.3100000023841858\n",
      "\n",
      "Best val_accuracy So Far: 0.6899999976158142\n",
      "Total elapsed time: 00h 00m 20s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_tfv_dense,y_train,epochs=5,validation_data=(X_test_tfv_dense,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9369df57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 7,\n",
       " 'units_0': 40,\n",
       " 'activation_0': 'relu',\n",
       " 'dropout_0': 0.30000000000000004,\n",
       " 'optimizer': 'nadam',\n",
       " 'units_1': 16,\n",
       " 'activation_1': 'relu',\n",
       " 'dropout_1': 0.0,\n",
       " 'units_2': 16,\n",
       " 'activation_2': 'relu',\n",
       " 'dropout_2': 0.0,\n",
       " 'units_3': 16,\n",
       " 'activation_3': 'relu',\n",
       " 'dropout_3': 0.0,\n",
       " 'units_4': 16,\n",
       " 'activation_4': 'relu',\n",
       " 'dropout_4': 0.0,\n",
       " 'units_5': 16,\n",
       " 'activation_5': 'relu',\n",
       " 'dropout_5': 0.0,\n",
       " 'units_6': 16,\n",
       " 'activation_6': 'relu',\n",
       " 'dropout_6': 0.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd91ce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 16ms/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.1895 - val_accuracy: 0.9438\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9922 - val_loss: 0.1979 - val_accuracy: 0.9375\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9922 - val_loss: 0.2033 - val_accuracy: 0.9438\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.2015 - val_accuracy: 0.9375\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0769 - accuracy: 0.9750 - val_loss: 0.2039 - val_accuracy: 0.9438\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0558 - accuracy: 0.9781 - val_loss: 0.2089 - val_accuracy: 0.9312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2178cb6a920>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tfv_dense,y_train,epochs=100,validation_split=0.2,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "552f8be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       138\n",
      "           1       1.00      0.90      0.95        62\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.98      0.95      0.96       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test_tfv)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbe0adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5899226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 11829\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(X_train)  # X_train should be a list of text data\n",
    "\n",
    "# Get vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for padding token\n",
    "\n",
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5835b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=11830, oov_token=\"<OOV>\")  # Keep 5000 most frequent words\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding (to ensure uniform input size)\n",
    "max_length = 100  # Max words per sentence\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5e319d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 128)          1514240   \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 100, 64)           49408     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 100, 64)           0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 100, 32)           12416     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1585473 (6.05 MB)\n",
      "Trainable params: 1585473 (6.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=11830, output_dim=128, input_length=max_length),  # Word embedding\n",
    "    LSTM(64, return_sequences=True),  # First LSTM layer (can add more layers if needed)\n",
    "    Dropout(0.3),\n",
    "    LSTM(32,return_sequences=True),  # Second LSTM layer\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab7c7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.2403e-05 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.9100\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.1542e-05 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.9100\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 4s 155ms/step - loss: 1.2454e-05 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9100\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 155ms/step - loss: 1.4456e-05 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.9100\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 1.3330e-05 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.9100\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 1.2581e-05 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=100, batch_size=32, validation_data=(X_test_pad, y_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9622c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 30ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       138\n",
      "           1       0.84      0.87      0.86        62\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.89      0.90      0.90       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9672d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
